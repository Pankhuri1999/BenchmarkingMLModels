{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lcdUg0_DfHF_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib.table import Table\n",
        "import os\n",
        "\n",
        "# Set style\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-darkgrid')\n",
        "except:\n",
        "    try:\n",
        "        plt.style.use('seaborn-darkgrid')\n",
        "    except:\n",
        "        plt.style.use('default')\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['font.size'] = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for all datasets\n",
        "datasets = {\n",
        "    'Student Performance': {\n",
        "        'XGBoost': {'MAE': 0.7274, 'RMSE': 1.9263, 'R2': 0.7375, 'MAPE': 1.04, 'Accuracy': 98.92, 'Fairness': 0.4186, 'Readiness': 18.69},\n",
        "        'RandomForest': {'MAE': 1.1197, 'RMSE': 2.1954, 'R2': 0.6590, 'MAPE': 1.63, 'Accuracy': 98.34, 'Fairness': 0.2309, 'Readiness': 17.30},\n",
        "        'LightGBM': {'MAE': 0.7314, 'RMSE': 1.9028, 'R2': 0.7439, 'MAPE': 1.04, 'Accuracy': 98.91, 'Fairness': 0.4249, 'Readiness': 17.72},\n",
        "        'LogisticRegression': {'MAE': 1.1172, 'RMSE': 2.2838, 'R2': 0.6310, 'MAPE': 1.62, 'Accuracy': 98.34, 'Fairness': 0.4619, 'Readiness': 17.16}\n",
        "    },\n",
        "    'University Ranking': {\n",
        "        'XGBoost': {'MAE': 368.81, 'RMSE': 486.46, 'R2': 0.2165, 'MAPE': 35.09, 'Accuracy': 95.9, 'Fairness': 0.0004, 'Readiness': 18.79},\n",
        "        'RandomForest': {'MAE': 368.04, 'RMSE': 482.22, 'R2': 0.2301, 'MAPE': 34.76, 'Accuracy': 95.9, 'Fairness': 0.0084, 'Readiness': 18.80},\n",
        "        'LightGBM': {'MAE': 364.51, 'RMSE': 476.47, 'R2': 0.2484, 'MAPE': 35.11, 'Accuracy': 95.9, 'Fairness': 0.0044, 'Readiness': 18.79},\n",
        "        'LogisticRegression': {'MAE': 939.08, 'RMSE': 1088.19, 'R2': -2.9204, 'MAPE': 99.67, 'Accuracy': 10.7, 'Fairness': 0.0014, 'Readiness': 12.54}\n",
        "    },\n",
        "    'Enrollment': {\n",
        "        'XGBoost': {'MAE': 235251, 'RMSE': 369604, 'R2': 0.9970, 'MAPE': 4.08, 'Accuracy': 99.7, 'Fairness': 398335, 'Readiness': 14.997},\n",
        "        'RandomForest': {'MAE': 226740, 'RMSE': 420093, 'R2': 0.9961, 'MAPE': 3.04, 'Accuracy': 99.6, 'Fairness': 106705, 'Readiness': 14.996},\n",
        "        'LightGBM': {'MAE': 1975339, 'RMSE': 2389779, 'R2': 0.8734, 'MAPE': 35.67, 'Accuracy': 87.3, 'Fairness': 1584734, 'Readiness': 14.873},\n",
        "        'LogisticRegression': {'MAE': 6036301, 'RMSE': 6349858, 'R2': 0.1063, 'MAPE': 245.16, 'Accuracy': 10.6, 'Fairness': 3093992, 'Readiness': 14.106}\n",
        "    },\n",
        "    'Dropout': {\n",
        "        'XGBoost': {'MAE': 0.306, 'RMSE': 0.444, 'R2': 0.4559, 'MAPE': int(float(\"1.355932e+09\")), 'Accuracy': 76.3, 'Fairness': 0.0271, 'Readiness': 18.81},\n",
        "        'RandomForest': {'MAE': 0.289, 'RMSE': 0.414, 'R2': 0.4932, 'MAPE': int(float(\"1.378531e+09\")), 'Accuracy': 77.3, 'Fairness': 0.0065, 'Readiness': 18.86},\n",
        "        'LightGBM': {'MAE': 0.303, 'RMSE': 0.441, 'R2': 0.4600, 'MAPE': int(float(\"1.401130e+09\")), 'Accuracy': 76.6, 'Fairness': 0.0068, 'Readiness': 18.83},\n",
        "        'LogisticRegression': {'MAE': 0.314, 'RMSE': 0.454, 'R2': 0.4434, 'MAPE': int(float(\"1.299435e+09\")), 'Accuracy': 75.6, 'Fairness': 0.0087, 'Readiness': 17.78}\n",
        "    },\n",
        "    'Budget Prediction': {\n",
        "        # Averages across 9 labels\n",
        "        'XGBoost': {'MAE': 0.0815, 'RMSE': 1.1606, 'R2': 0.9318, 'MAPE': 2.3151, 'Accuracy': 98.52, 'Fairness': 0.0009, 'Readiness': 19.90},\n",
        "        'RandomForest': {'MAE': 1.5031, 'RMSE': 22.0941, 'R2': 0.2156, 'MAPE': 38.8370, 'Accuracy': 77.40, 'Fairness': 0.0008, 'Readiness': 18.76},\n",
        "        'LightGBM': {'MAE': 2.2800, 'RMSE': 50.1843, 'R2': 0.6690, 'MAPE': 40.8317, 'Accuracy': 76.00, 'Fairness': 0.0015, 'Readiness': 19.20},\n",
        "        'LogisticRegression': {'MAE': 0.1042, 'RMSE': 1.3952, 'R2': 0.9140, 'MAPE': 2.8706, 'Accuracy': 97.86, 'Fairness': 0.0011, 'Readiness': 18.89}\n",
        "    }\n",
        "}\n",
        "\n",
        "models = ['XGBoost', 'RandomForest', 'LightGBM', 'LogisticRegression']\n",
        "\n"
      ],
      "metadata": {
        "id": "YGESDoPngaHP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_number(value, metric_type):\n",
        "    \"\"\"Format numbers for display\"\"\"\n",
        "    if value is None:\n",
        "        return 'N/A'\n",
        "\n",
        "    if metric_type == 'MAE':\n",
        "        if value >= 1000:\n",
        "            return f'{value/1000:.1f}K' if value < 1000000 else f'{value/1000000:.2f}M'\n",
        "        return f'{value:.4f}' if value < 1 else f'{value:.2f}'\n",
        "    elif metric_type == 'RMSE':\n",
        "        if value >= 1000:\n",
        "            return f'{value/1000:.1f}K' if value < 1000000 else f'{value/1000000:.2f}M'\n",
        "        return f'{value:.4f}' if value < 1 else f'{value:.2f}'\n",
        "    elif metric_type == 'R2':\n",
        "        return f'{value:.4f}'\n",
        "    elif metric_type == 'MAPE':\n",
        "        return f'{value:.2f}%'\n",
        "    elif metric_type == 'Accuracy':\n",
        "        return f'{value:.2f}%'\n",
        "    elif metric_type == 'Fairness':\n",
        "        if value >= 1000:\n",
        "            return f'{value/1000:.1f}K' if value < 1000000 else f'{value/1000000:.2f}M'\n",
        "        return f'{value:.4f}'\n",
        "    elif metric_type == 'Readiness':\n",
        "        return f'{value:.2f}'\n",
        "    return str(value)\n"
      ],
      "metadata": {
        "id": "oOzUtLh9gaLx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_performance_table(dataset_name, data, output_path):\n",
        "    \"\"\"Create performance metrics table\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Prepare data\n",
        "    table_data = []\n",
        "    for model in models:\n",
        "        row = [\n",
        "            model,\n",
        "            format_number(data[model]['MAE'], 'MAE'),\n",
        "            format_number(data[model]['RMSE'], 'RMSE'),\n",
        "            format_number(data[model]['R2'], 'R2'),\n",
        "            format_number(data[model]['MAPE'], 'MAPE') if data[model]['MAPE'] is not None else 'N/A',\n",
        "            format_number(data[model]['Accuracy'], 'Accuracy')\n",
        "        ]\n",
        "        table_data.append(row)\n",
        "\n",
        "    # Create table\n",
        "    table = ax.table(cellText=table_data,\n",
        "                     colLabels=['Model', 'MAE', 'RMSE', 'R²', 'MAPE (%)', 'Accuracy (%)'],\n",
        "                     cellLoc='center',\n",
        "                     loc='center',\n",
        "                     bbox=[0, 0, 1, 1])\n",
        "\n",
        "    # Style table\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(11)\n",
        "    table.scale(1, 2.5)\n",
        "\n",
        "    # Color header\n",
        "    for i in range(6):\n",
        "        table[(0, i)].set_facecolor('#4472C4')\n",
        "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "    # Highlight best values\n",
        "    metrics = ['MAE', 'RMSE', 'R2', 'MAPE', 'Accuracy']\n",
        "    metric_indices = [1, 2, 3, 4, 5]\n",
        "\n",
        "    for idx, metric in zip(metric_indices, metrics):\n",
        "        if metric == 'MAPE' and dataset_name == 'Dropout':\n",
        "            continue  # Skip MAPE for Dropout\n",
        "\n",
        "        values = []\n",
        "        for model in models:\n",
        "            val = data[model][metric]\n",
        "            if val is not None:\n",
        "                values.append(val)\n",
        "\n",
        "        if values:\n",
        "            if metric in ['MAE', 'RMSE', 'MAPE']:\n",
        "                best_idx = np.argmin(values)\n",
        "            else:  # R2, Accuracy\n",
        "                best_idx = np.argmax(values)\n",
        "\n",
        "            best_model_idx = [i for i, v in enumerate([data[m][metric] for m in models]) if v == values[best_idx]][0]\n",
        "            table[(best_model_idx + 1, idx)].set_facecolor('#90EE90')\n",
        "\n",
        "    # Style model names\n",
        "    for i in range(1, 5):\n",
        "        table[(i, 0)].set_facecolor('#E7E6E6')\n",
        "        table[(i, 0)].set_text_props(weight='bold')\n",
        "\n",
        "    plt.title(f'Performance Metrics Summary - {dataset_name}', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.savefig(output_path, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "    plt.close()\n",
        "    print(f'Created: {output_path}')\n"
      ],
      "metadata": {
        "id": "RK_9aj-_gaQa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fairness_table(dataset_name, data, output_path):\n",
        "    \"\"\"Create fairness summary table\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Prepare data\n",
        "    table_data = []\n",
        "    for model in models:\n",
        "        disparity = data[model]['Fairness']\n",
        "        table_data.append([model, format_number(disparity, 'Fairness')])\n",
        "\n",
        "    # Create table\n",
        "    table = ax.table(cellText=table_data,\n",
        "                     colLabels=['Model', 'Disparity (Lower is Better)'],\n",
        "                     cellLoc='center',\n",
        "                     loc='center',\n",
        "                     bbox=[0, 0, 1, 1])\n",
        "\n",
        "    # Style table\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(12)\n",
        "    table.scale(1, 3)\n",
        "\n",
        "    # Color header\n",
        "    for i in range(2):\n",
        "        table[(0, i)].set_facecolor('#4472C4')\n",
        "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "    # Highlight best (lowest disparity)\n",
        "    disparities = [data[model]['Fairness'] for model in models]\n",
        "    best_idx = np.argmin(disparities)\n",
        "    table[(best_idx + 1, 1)].set_facecolor('#90EE90')\n",
        "\n",
        "    # Style model names\n",
        "    for i in range(1, 5):\n",
        "        table[(i, 0)].set_facecolor('#E7E6E6')\n",
        "        table[(i, 0)].set_text_props(weight='bold')\n",
        "\n",
        "    plt.title(f'Fairness Summary - {dataset_name}', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.savefig(output_path, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "    plt.close()\n",
        "    print(f'Created: {output_path}')\n"
      ],
      "metadata": {
        "id": "01PWo4fygait"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_readiness_table(dataset_name, data, output_path):\n",
        "    \"\"\"Create readiness summary table\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Prepare data\n",
        "    table_data = []\n",
        "    for model in models:\n",
        "        readiness = data[model]['Readiness']\n",
        "        table_data.append([model, format_number(readiness, 'Readiness')])\n",
        "\n",
        "    # Create table\n",
        "    table = ax.table(cellText=table_data,\n",
        "                     colLabels=['Model', 'Total Readiness Score'],\n",
        "                     cellLoc='center',\n",
        "                     loc='center',\n",
        "                     bbox=[0, 0, 1, 1])\n",
        "\n",
        "    # Style table\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(12)\n",
        "    table.scale(1, 3)\n",
        "\n",
        "    # Color header\n",
        "    for i in range(2):\n",
        "        table[(0, i)].set_facecolor('#4472C4')\n",
        "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "    # Highlight best (highest readiness)\n",
        "    readiness_scores = [data[model]['Readiness'] for model in models]\n",
        "    best_idx = np.argmax(readiness_scores)\n",
        "    table[(best_idx + 1, 1)].set_facecolor('#90EE90')\n",
        "\n",
        "    # Style model names\n",
        "    for i in range(1, 5):\n",
        "        table[(i, 0)].set_facecolor('#E7E6E6')\n",
        "        table[(i, 0)].set_text_props(weight='bold')\n",
        "\n",
        "    plt.title(f'Readiness Summary - {dataset_name}', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.savefig(output_path, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "    plt.close()\n",
        "    print(f'Created: {output_path}')\n"
      ],
      "metadata": {
        "id": "SdwGAxayg8D6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate all visualization images\n",
        "output_dir = 'metrics_visualizations'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Generate images for each dataset\n",
        "for dataset_name, data in datasets.items():\n",
        "    # Clean dataset name for filename\n",
        "    filename_base = dataset_name.replace(' ', '_').lower()\n",
        "\n",
        "    # Performance metrics\n",
        "    perf_path = f'{output_dir}/{filename_base}_performance_metrics.png'\n",
        "    create_performance_table(dataset_name, data, perf_path)\n",
        "\n",
        "    # Fairness summary\n",
        "    fairness_path = f'{output_dir}/{filename_base}_fairness_summary.png'\n",
        "    create_fairness_table(dataset_name, data, fairness_path)\n",
        "\n",
        "    # Readiness summary\n",
        "    readiness_path = f'{output_dir}/{filename_base}_readiness_summary.png'\n",
        "    create_readiness_table(dataset_name, data, readiness_path)\n",
        "\n",
        "print(f'\\n✅ All visualizations generated in \\'{output_dir}\\' directory!')\n",
        "print(f'   Total: {len(datasets) * 3} images created')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c8L585dgapH",
        "outputId": "536164e9-6748-490e-cd0d-1640e620c2f2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: metrics_visualizations/student_performance_performance_metrics.png\n",
            "Created: metrics_visualizations/student_performance_fairness_summary.png\n",
            "Created: metrics_visualizations/student_performance_readiness_summary.png\n",
            "Created: metrics_visualizations/university_ranking_performance_metrics.png\n",
            "Created: metrics_visualizations/university_ranking_fairness_summary.png\n",
            "Created: metrics_visualizations/university_ranking_readiness_summary.png\n",
            "Created: metrics_visualizations/enrollment_performance_metrics.png\n",
            "Created: metrics_visualizations/enrollment_fairness_summary.png\n",
            "Created: metrics_visualizations/enrollment_readiness_summary.png\n",
            "Created: metrics_visualizations/dropout_performance_metrics.png\n",
            "Created: metrics_visualizations/dropout_fairness_summary.png\n",
            "Created: metrics_visualizations/dropout_readiness_summary.png\n",
            "Created: metrics_visualizations/budget_prediction_performance_metrics.png\n",
            "Created: metrics_visualizations/budget_prediction_fairness_summary.png\n",
            "Created: metrics_visualizations/budget_prediction_readiness_summary.png\n",
            "\n",
            "✅ All visualizations generated in 'metrics_visualizations' directory!\n",
            "   Total: 15 images created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UeGnJkfWgauu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlYMqW_1ga0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhF50CV1ga7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cTRTfijhgbCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KwIUHUYigbI_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}